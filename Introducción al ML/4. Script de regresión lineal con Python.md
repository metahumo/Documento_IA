# Script de regresión lineal con Python: Explicación completa

## 1. Introducción

En este documento explicamos paso a paso la construcción de un script en Python para entrenar un modelo de regresión lineal que predice grados Fahrenheit a partir de grados Celsius. El objetivo es entender el flujo de trabajo básico de machine learning con pandas, seaborn y scikit-learn.

### 1.1 Creamos documento .csv

Debemos tener en el directorio donde se ejecute el script un archivo `celsius.csv` con la siguiente información:

```csv
celsius,fahrenheit
-40,-40
-10,14
0,32
8,46.4
15,59
```

### 1.2. Creamos un entorno virtual en el que instalar todas las dependencias (para Windows estos son los comandos)

Desde la terminal:

```
python -m venv env  
.\env\Scripts\Activate.ps1
```

### 1.3. Instalamos las dependencias necesarias

Desde la terminal:

```
pip install pandas  
pip install seaborn
pip install scikit-learn
```


---

## 2. Importación de librerías

```python
import pandas as pd
import seaborn as sb
from sklearn.linear_model import LinearRegression
```

- **pandas** para cargar y gestionar datos tabulares.
    
- **seaborn** para visualización.
    
- **LinearRegression** de scikit-learn para crear y entrenar el modelo.
    


---

## 3. Carga y exploración de datos

```python
datos = pd.read_csv("celsius.csv")

datos.info()
datos.head()
```

- `read_csv()` carga el dataset desde un archivo CSV.
    
- `info()` muestra tipos de datos y valores nulos.
    
- `head()` visualiza las primeras filas.
    

Esto permite validar que el dataset contiene columnas `celsius` y `fahrenheit`.

---

## 4. Visualización de datos

```python
sb.scatterplot(x="celsius", y="fahrenheit", data=datos,
               hue="fahrenheit", palette="coolwarm")
```

Se crea un gráfico de dispersión para observar la relación entre ambas variables. Esto ayuda a ver si el comportamiento es lineal.

---

## 5. Separación de características y etiquetas

```python
X = datos["celsius"]
y = datos["fahrenheit"]

print(X, y)
```

- **X** es la variable independiente (celsius).
    
- **y** es la variable objetivo (fahrenheit).
    

---

## 6. Transformación de datos

```python
X_procesada = X.values.reshape(-1,1)
y_procesada = y.values.reshape(-1,1)
```

scikit-learn espera matrices 2D, por eso transformamos los vectores.

Ejemplo de salida esperada:

```
[-40] [-10] [0] [8] ...
```

---

## 7. Creación y entrenamiento del modelo

```python
modelo = LinearRegression()

modelo.fit(X_procesada, y_procesada)
```

- Se instancia el modelo.
    
- Se entrena con datos reales.
    

Durante el entrenamiento, el algoritmo calcula la mejor línea que minimiza el error.

---

## 8. Predicción con el modelo

```python
celsius = 100
prediccion = modelo.predict([[celsius]])
print(f"{celsius} grados celsius son {prediccion} grados fahrenheit")
```

Se realiza una predicción para un valor específico.

Salida esperada aproximada:

```
100 grados celsius son [[212.]] grados fahrenheit
```

---

## 9. Evaluación del modelo

```python
print(modelo.score(X_procesada, y_procesada))
```

El método `score()` devuelve el coeficiente R², que indica cuánto explican los datos a la variable objetivo (ideal cercano a 1.0).

---

## 10. Resumen del flujo completo

1. Cargar y explorar datos.
    
2. Visualizar relación.
    
3. Separar variables.
    
4. Preparar matrices.
    
5. Instanciar modelo.
    
6. Entrenar.
    
7. Predecir.
    
8. Evaluar.
    

---

## 11. Conexión con machine learning

Este script es un ejemplo clásico de **aprendizaje supervisado en regresión**, ideal para comprender los conceptos básicos:

- Datos históricos con relación lineal.
    
- Modelo interpretable.
    
- Métricas sencillas.
    

Es una base sólida antes de abordar modelos avanzados con múltiples variables y redes neuronales.


## Script completo

```python
import pandas as pd
import seaborn as sb
from sklearn.linear_model import LinearRegression

datos = pd.read_csv("celsius.csv")


datos.info()
datos.head() 

sb.scatterplot(x="celsius", y="fahrenheit", data=datos,
               hue="fahrenheit", palette="coolwarm")  

# Características (X), etiqueta(y)  

X = datos["celsius"]
y = datos["fahrenheit"] 

print(X, y)

# X.values
# [-40, -10, 0, 8, ...]
# [[-40], [-10], [0], [8], ...]

X_procesada = X.values.reshape(-1,1)
y_procesada = y.values.reshape(-1,1)

modelo = LinearRegression() 

# Entrenamiento  

modelo.fit(X_procesada, y_procesada)
celsius = 100
prediccion = modelo.predict([[celsius]])

print(f"{celsius} grados celsius son {prediccion} grados fahrenheit")

print(modelo.score(X_procesada, y_procesada))
```
## Salida esperada

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5 entries, 0 to 4
Data columns (total 2 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   celsius     5 non-null      int64  
 1   fahrenheit  5 non-null      float64
dtypes: float64(1), int64(1)
memory usage: 212.0 bytes

0   -40
1   -10
2     0
3     8
4    15
Name: celsius, dtype: int64

0   -40.0
1    14.0
2    32.0
3    46.4
4    59.0
Name: fahrenheit, dtype: float64

100 grados celsius son [[212.]] grados fahrenheit

1.0
```

## Visualización de gráficas en Python para este contexto

Cuando trabajamos con scripts de Python fuera de entornos como Google Colab o Jupyter Notebook, las gráficas generadas con **Seaborn** o **Matplotlib** **no se muestran automáticamente**. Esto se debe a que, en un script local, la figura se crea en memoria pero no se abre ninguna ventana de visualización a menos que se lo indiquemos explícitamente.

Para este script de regresión lineal (Celsius → Fahrenheit), podemos añadir la visualización de la siguiente manera:

```python
import matplotlib.pyplot as plt
import seaborn as sb

# Gráfico de dispersión
sb.scatterplot(x="celsius", y="fahrenheit", data=datos,
               hue="fahrenheit", palette="coolwarm")

# Título opcional
plt.title("Relación entre Celsius y Fahrenheit")

# Mostrar la gráfica
plt.show()
````

### Explicación:

1. `plt.title()` añade un título a la gráfica para facilitar la interpretación.
    
2. `plt.show()` es **esencial en scripts locales**, ya que fuerza a que se abra la ventana de la figura.
    
3. En Google Colab o Jupyter Notebook, `plt.show()` no es estrictamente necesario porque las gráficas se renderizan automáticamente “inline”.
    
4. Alternativamente, si no se dispone de un entorno gráfico, se puede **guardar la figura** con:
    
    ```python
    plt.savefig("grafica.png", dpi=300)
    ```
    
    Esto genera un archivo de imagen que puede revisarse posteriormente.
    

Con esto, podemos inspeccionar visualmente la relación entre las variables antes de entrenar el modelo de regresión, lo cual es útil para validar la linealidad y detectar posibles outliers.